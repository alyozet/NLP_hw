{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2_NLP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3l0NcYBHuYu"
      },
      "source": [
        "#ДЗ 2 по АОТ\n",
        "сначала скачаем и импортируем все что нам надо\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HpgSqgnHmFQ",
        "outputId": "53994540-a94b-4229-e2c0-a3586880fcde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install natasha\n",
        "!pip install pymorphy2\n",
        "!pip install git+https://github.com/nlpub/pymystem3\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install flair\n",
        "!pip install nltk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: natasha in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: slovnet>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.4.0)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: yargy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.14.0)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from slovnet>=0.3.0->natasha) (1.18.5)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.6/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.2.2)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting git+https://github.com/nlpub/pymystem3\n",
            "  Cloning https://github.com/nlpub/pymystem3 to /tmp/pip-req-build-7sgwvd1p\n",
            "  Running command git clone -q https://github.com/nlpub/pymystem3 /tmp/pip-req-build-7sgwvd1p\n",
            "Requirement already satisfied (use --upgrade to upgrade): pymystem3==0.2.0 from git+https://github.com/nlpub/pymystem3 in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pymystem3==0.2.0) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (2020.6.20)\n",
            "Building wheels for collected packages: pymystem3\n",
            "  Building wheel for pymystem3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymystem3: filename=pymystem3-0.2.0-cp36-none-any.whl size=9922 sha256=2160c3c2ec9029ec67da85953e38b330445e566598a480bd1c6d81eb8099f6f0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l1tnuv7o/wheels/7d/75/c2/216a594291dee680749ce12c60d16125cfe1f363059e7163dc\n",
            "Successfully built pymystem3\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.2.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.3.1)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.1)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.10)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.10)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from flair) (5.8)\n",
            "Requirement already satisfied: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (6.1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.91)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.8)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0+cu101)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.7.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.8.1rc2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.7)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.15.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (2.0.0)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.10.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.2.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.13.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.16.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (2.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied: overrides==3.0.0 in /usr/local/lib/python3.6/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.0->flair) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (1.24.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY6DCYMDI4w1",
        "outputId": "c3f5eb41-c681-44c3-ed99-6100211200ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    \n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    NewsNERTagger,\n",
        "    \n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "\n",
        "    Doc\n",
        ")\n",
        "import pymorphy2\n",
        "m = pymorphy2.MorphAnalyzer()\n",
        "from pymorphy2.tokenizers import simple_word_tokenize\n",
        "from pymystem3 import Mystem\n",
        "m2 = Mystem()\n",
        "import spacy\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0c8qikiJWre"
      },
      "source": [
        "Добавим тексты:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzN7WmWpJ-F2"
      },
      "source": [
        "rutext = '''Я быстро вставила в ухо красивую сережку. Сережка громко засмеялся. На Тянь-Шане было очень холодно. Всю знать позвали на пышный обед. Его френдята на Фейсбуке поставили мне дохера лайков. Калтывый бусик ударил шонку. Кринжовая ситуэйшен произошла со мной на прошлых выходных. Эта девочка была ультраженственной. Френдя знакомых в тиктоке, она испытывала очень странные ощущения. Она тогда была уехалши. Не емши, он вышел на лестничную клетку. Я висю на турнике и пытаюсь подтянуться. Этот новенький деревяннее некуда. Дежурный снова курит айкос. Я в прошлом году поступил в МГУ. Я ездила во Мгу на этих выходных. Она тогда была увезена в тайгу.'''\n",
        "entext = '''I gollowed the nusk. I will be gollowing this soon. This gollowing will kill me. I don’t have a permit to do this. I watched him killing Eve. I’m waiting for a Christmas Eve to pass. Lying to me won’t make our relationship work. I want to object. This object looks very roundish. I look at his progress every day. I progress slowly in maths. I’ll be home at seventish. The waiting area was huge. I am waiting for you. This made me go numb. This made bed looked lonely. My weekly routine is quite boring. I do this weekly.'''\n",
        "textn = 'I gollowed the nusk. I will be gollowing this soon. This gollowing will kill me. I do not have a permit to do this. I watched him killing Eve. I am waiting for a Christmas Eve to pass. Lying to me will not make our relationship work. I want to object. This object looks very roundish. I look at his progress every day. I progress slowly in maths. I will be home at seventish. The waiting area was huge. I am waiting for you. This made me go numb. This made bed looked lonely. My weekly routine is quite boring. I do this weekly.'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpXWCu8pK8Sg"
      },
      "source": [
        "Почему три текста? Потому что nltk не умеет нормально парсить слова типа don't, и я для него их заменила на do not, а так ничего не меняла."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syvEWnuyLIrU"
      },
      "source": [
        "###Русский:\n",
        "Я быстро вставила в ухо красивую сережку. Сережка громко засмеялся. На Тянь-Шане было очень холодно. Всю знать позвали на пышный обед. Его френдята на Фейсбуке поставили мне дохера лайков. Калтывый бусик ударил шонку. Кринжовая ситуэйшен произошла со мной на прошлых выходных. Эта девочка была ультраженственной. Френдя знакомых в тиктоке, она испытывала очень странные ощущения. Она тогда была уехалши. Не емши, он вышел на лестничную клетку. Я висю на турнике и пытаюсь подтянуться. Этот новенький деревяннее некуда. Дежурный снова курит айкос. Я в прошлом году поступил в МГУ. Я ездила во Мгу на этих выходных. Она тогда была увезена в тайгу.\n",
        "\n",
        "Тут разные слова, которые затрудняют парсерам жизнь: слова, которые могут быть разными частями речи, имена собственные, неологизмы, ненастоящие слова, деепричастия, диалектные варианты и другое."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPU1ILcaLsNX"
      },
      "source": [
        "###Английский\n",
        "I gollowed the nusk. I will be gollowing this soon. This gollowing will kill me. I don’t have a permit to do this. I watched him killing Eve. I’m waiting for a Christmas Eve to pass. Lying to me won’t make our relationship work. I want to object. This object looks very roundish. I look at his progress every day. I progress slowly in maths. I’ll be home at seventish. The waiting area was huge. I am waiting for you. This made me go numb. This made bed looked lonely. My weekly routine is quite boring. I do this weekly.\n",
        "\n",
        "Тут тоже слова, которые трудно парсить: ненастоящие, существительные-глаголы, имена собственные, разговорные, причастия, местоимения-детерминаторы, прилагательные-наречия."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWi0H8b0MnJM"
      },
      "source": [
        "Мои разборы подгрузим с компа:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIgkKVdbI6lo"
      },
      "source": [
        "def upload(name):\n",
        "  with open(name, encoding='utf-8') as f:\n",
        "    pos = f.read()\n",
        "    s = pos.split('\\n')\n",
        "    poss = [i.split(' ') for i in s]\n",
        "  return(poss)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A90VHlbhM9yj"
      },
      "source": [
        "rupos = upload('RUPOS.txt')\n",
        "enpos = upload('ENPOS.txt')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W2kb40yNTj5"
      },
      "source": [
        "###Наташа\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4mi-ACXNcBa"
      },
      "source": [
        "def nat(rutext):\n",
        "  segmenter = Segmenter()\n",
        "  emb = NewsEmbedding()\n",
        "  morph_tagger = NewsMorphTagger(emb)\n",
        "  syntax_parser = NewsSyntaxParser(emb)\n",
        "  ner_tagger = NewsNERTagger(emb)\n",
        "  doc =  Doc(rutext)\n",
        "  doc.segment(segmenter)\n",
        "  doc.tag_morph(morph_tagger)\n",
        "  natwordpos = []\n",
        "  for i in doc.sents:\n",
        "    for j in i.morph.tokens:\n",
        "      natwordpos.append([j.text, j.pos])\n",
        "  return([i for i in natwordpos if i[0] not in ['.', ',']])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcSuHkVROOcL"
      },
      "source": [
        "###Pymorphy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45NKljgZORxg"
      },
      "source": [
        "def pymorphy1(rutext):\n",
        "  ruwords = simple_word_tokenize(rutext)\n",
        "  pymwordpos = []\n",
        "  for i in ruwords:\n",
        "    pymwordpos.append([i, m.parse(i)[0].tag.POS])\n",
        "  return([i for i in pymwordpos if i[0] not in ['.', ',']])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPyKPqhDQAr2"
      },
      "source": [
        "###Mystem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3_i2LkwdUYY",
        "outputId": "37e3d65e-16ac-40c4-ac14-1cba44b438d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!cp mystem /root/.local/bin/mystem"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-13 11:00:49--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.245, 5.45.205.241, 5.45.205.242, ...\n",
            "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.245|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://cache-mskm903.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz [following]\n",
            "--2020-10-13 11:00:49--  http://cache-mskm903.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving cache-mskm903.cdn.yandex.net (cache-mskm903.cdn.yandex.net)... 5.45.220.13, 2a02:6b8:0:2002::14\n",
            "Connecting to cache-mskm903.cdn.yandex.net (cache-mskm903.cdn.yandex.net)|5.45.220.13|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16457938 (16M) [application/octet-stream]\n",
            "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.2’\n",
            "\n",
            "mystem-3.0-linux3.1 100%[===================>]  15.70M  31.0MB/s    in 0.5s    \n",
            "\n",
            "2020-10-13 11:00:50 (31.0 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.2’ saved [16457938/16457938]\n",
            "\n",
            "mystem\n",
            "cp: cannot create regular file '/root/.local/bin/mystem': Text file busy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XsND-i5dXXQ"
      },
      "source": [
        "def myst(rutext):\n",
        "  ana = m2.analyze(rutext)\n",
        "  myswordpos = []\n",
        "  for word in ana:\n",
        "    if 'analysis' in word:\n",
        "      gr = word['analysis'][0]['gr']\n",
        "      pos = gr.split('=')[0].split(',')[0]\n",
        "      myswordpos.append([word['text'], pos])\n",
        "  return(myswordpos)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baoOM4VcQQ--"
      },
      "source": [
        "###Spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa9RgNXoQEfh"
      },
      "source": [
        "def spacy1(entext):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(entext)\n",
        "  spawordpos = []\n",
        "  for i, s in enumerate(doc.sents):\n",
        "    for t in s:\n",
        "      spawordpos.append([t.text, t.pos_])\n",
        "  return([i for i in spawordpos if i[0] != '.'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFugQYCdQptE"
      },
      "source": [
        "###Flair\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0frV70NQsQ1"
      },
      "source": [
        "def flair1(entext):\n",
        "  sentence = Sentence(entext)\n",
        "  tagger = SequenceTagger.load('pos')\n",
        "  tagger.predict(sentence)\n",
        "  x = sentence.to_tagged_string()\n",
        "  y = x.split(' ')\n",
        "  flawordpos = []\n",
        "  for i in range(0, len(y), 2):\n",
        "    flawordpos.append([y[i], y[i+1]])\n",
        "  return([i for i in flawordpos if i[0] != '.'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKcnCDdCQ9yc"
      },
      "source": [
        "###NLTK\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_D3jDWRQ9RD"
      },
      "source": [
        "def nltk1(textn):\n",
        "  words = word_tokenize(textn)\n",
        "  nltkwordpos1 = nltk.pos_tag(words)\n",
        "  nltkwordpos = []\n",
        "  for i, j in nltkwordpos1:\n",
        "    nltkwordpos.append([i, j])\n",
        "  return([i for i in nltkwordpos if i[0] != '.'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_AL3VtPRT0W"
      },
      "source": [
        "Напишем функцию, которая будет приводить все тэги к единому виду."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLWjskxnRbwo"
      },
      "source": [
        "def sync(wp):\n",
        "  tags = {\n",
        "    'NOUN': 'NOUN', \n",
        "    'PROPN': 'NOUN',\n",
        "    '<NN>': 'NOUN',\n",
        "    'ADJF': 'ADJ',\n",
        "    'ADJ': 'ADJ',\n",
        "    'ADJS': 'ADJ',\n",
        "    'COMP': 'ADJ', \n",
        "    'VERB': 'VERB',\n",
        "    'INFN': 'VERB',\n",
        "    'PRTF': 'VERB',\n",
        "    'PRTS': 'VERB',\n",
        "    'GRND': 'VERB',\n",
        "    'AUX': 'VERB',\n",
        "    '<VB>': 'VERB',\n",
        "    '<VBP>': 'VERB',\n",
        "    '<VBD>': 'VERB',\n",
        "    '<VBG>': 'VERB',\n",
        "    '<VBZ>': 'VERB',\n",
        "    'NUMR': 'NUM',\n",
        "    'NUM': 'NUM',\n",
        "    'ADVB': 'ADV',\n",
        "    'ADV': 'ADV',\n",
        "    '<RB>': 'ADV',\n",
        "    'NPRO': 'PRON',\n",
        "    'PRON': 'PRON',\n",
        "    'PRED': 'VERB',\n",
        "    'PREP': 'ADP',\n",
        "    'ADP' : 'ADP',\n",
        "    '<PRP>' : 'PRON',\n",
        "    'CONJ': 'CCONJ',\n",
        "    'CCONJ': 'CCONJ',\n",
        "    'PRCL': 'PART',\n",
        "    'PART': 'PART',\n",
        "    'INTJ': 'NONE',\n",
        "    'NONE': 'NONE',\n",
        "    'PUNCT': 'NONE',\n",
        "    'X': 'NONE',\n",
        "    '<.>': 'NONE',\n",
        "    '.': 'NONE',\n",
        "    'DET': 'DET',\n",
        "    '<DT>': 'DET',\n",
        "    '<JJ>': 'ADJ',\n",
        "    '<IN>': 'ADP',\n",
        "    '<TO>': 'PART',\n",
        "    '<NNP>': 'NOUN',\n",
        "    '<PRP$>': 'DET',\n",
        "    '<NNS>': 'NOUN',\n",
        "    '<,>': 'NONE',\n",
        "    '<MD>': 'VERB',\n",
        "    'PRP': 'PRON',\n",
        "    'DT': 'DET',\n",
        "    'NN': 'NOUN',\n",
        "    'VBP': 'VERB',\n",
        "    'JJ': 'ADJ',\n",
        "    'VB': 'VERB',\n",
        "    'VBD': 'VERB',\n",
        "    'VBG': 'VERB',\n",
        "    'RB': 'ADV',\n",
        "    'IN': 'ADP',\n",
        "    'TO': 'PART',\n",
        "    'NNS': 'NOUN',\n",
        "    'NNP': 'NOUN',\n",
        "    'PRP$': 'DET',\n",
        "    'MD': 'VERB',\n",
        "    'VBZ': 'VERB',\n",
        "    'VBN': 'VERB',\n",
        "    'S': 'NOUN',\n",
        "    'V': 'VERB', \n",
        "    'PR': 'ADP', \n",
        "    'SPRO': 'PRON', \n",
        "    'A': 'ADJ',\n",
        "    'APRO': 'DET', \n",
        "    'ADVPRO': 'ADV',\n",
        "    'CONJ': 'CCONJ',\n",
        "    None: 'NONE'\n",
        "  }\n",
        "  new = [[i[0], tags[i[1]]] for i in wp]\n",
        "  return(new)\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf9DVp4mRzbA"
      },
      "source": [
        "Теперь напишем функцию, которая считает точность.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp6ln6gSR8al"
      },
      "source": [
        "def accuracy(wp, lang):\n",
        "  c = 0\n",
        "  for i in range(len(lang)):\n",
        "    if wp[i][1]==lang[i][1]:\n",
        "      c += 1\n",
        "  return(c/len(lang))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPpOuNEjSAGu"
      },
      "source": [
        "А теперь их все выполним и посчитаем!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCYfnFEKSEpp",
        "outputId": "69c2726b-9755-4132-b47c-ac77a0b7d0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "nata = sync(nat(rutext))\n",
        "pym = sync(pymorphy1(rutext))\n",
        "mys=sync(myst(rutext))\n",
        "ru = sync(rupos)\n",
        "\n",
        "spa = sync(spacy1(entext))\n",
        "fla = sync(flair1(entext))\n",
        "nlt = sync(nltk1(textn))\n",
        "en = sync(enpos)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-13 11:54:59,649 loading file /root/.flair/models/en-pos-ontonotes-v0.5.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSYVquwHUKmz",
        "outputId": "bb9253c8-364e-4b8a-f714-d3155bc4ebea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "print('Наташа '+str(accuracy(nata, ru)))\n",
        "print('Pymorphy '+str(accuracy(pym, ru)))\n",
        "print('Mystem '+str(accuracy(mys, ru)))\n",
        "print('')\n",
        "print('Spacy '+str(accuracy(spa, en))[:4])\n",
        "print('Flair '+str(accuracy(fla, en))[:4])\n",
        "print('NLTK '+str(accuracy(nlt, en))[:4])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Наташа 0.91\n",
            "Pymorphy 0.81\n",
            "Mystem 0.92\n",
            "\n",
            "Spacy 0.92\n",
            "Flair 0.90\n",
            "NLTK 0.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGFVstp3VEJH"
      },
      "source": [
        "###Выводы\n",
        "Mystem лучше всех для русского (92%)\n",
        "Наташа немного остает (91%)\n",
        "Pymorphy сильно хуже (81%)\n",
        "\n",
        "Spacy лучше всех для английского (92%)\n",
        "Flair немного отстает (90%)\n",
        "NLTK сильно хуже (83%)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4q7eA2zxO6H"
      },
      "source": [
        "###Бонус\n",
        "Сложные слова: слова, в которых парсеры ошибались."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg-zfLXfvISc"
      },
      "source": [
        "def hard(lang, f, s, t):\n",
        "  hard1 = []\n",
        "  for i in range(len(lang)):\n",
        "    if not (lang[i][1] == f[i][1] == s[i][1] == t[i][1]):\n",
        "      hard1.append(lang[i][0])\n",
        "  return(hard1)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljoBdgQExhgy",
        "outputId": "00af5c6d-de21-472d-f72f-dfd9a418f11b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "ruhard = hard(ru, nata, pym, mys)\n",
        "enhard = hard(en, spa, fla, nlt)\n",
        "print('Сложных русских слов: '+str(len(ruhard)))\n",
        "print(', '.join(ruhard))\n",
        "print('Сложных английских слов: '+str(len(enhard)))\n",
        "print(', '.join(enhard))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Сложных русских слов: 25\n",
            "холодно, Всю, знать, Его, френдята, дохера, лайков, Калтывый, Кринжовая, ситуэйшен, выходных, Эта, ультраженственной, Френдя, знакомых, уехалши, емши, висю, Этот, новенький, деревяннее, некуда, Дежурный, этих, выходных\n",
            "Сложных английских слов: 17\n",
            "this, gollowing, n’t, this, to, n’t, work, object, home, seventish, waiting, This, numb, made, lonely, this, weekly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYVKGQkNzWF9"
      },
      "source": [
        "Показатели точности в процентах для русского и английского близкие, а в русском сложных слов больше, значит, английские парсеры делает ошибки в одних и тех же местах, а русские -  в разных."
      ]
    }
  ]
}