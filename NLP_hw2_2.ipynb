{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_hw1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IrpZ6tURf6v"
      },
      "source": [
        "Домашнее задание по АОТ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIv6yYm3ISba"
      },
      "source": [
        "#это переделка первого ДЗ с учётом биграмм, читать где-то с середины, где начинается новое"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VF_3T3t8fRW",
        "outputId": "4d793ec1-6a7e-4414-dc26-190672f5c6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "! pip install requests\n",
        "! pip install nltk\n",
        "! pip install pymorphy2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.6.20)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ1QuzpR8whA",
        "outputId": "71debe05-2340-46bc-c5f3-90f62a06ed69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import requests\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()\n",
        "from collections import Counter\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU5GAPt3Rnw3"
      },
      "source": [
        "Я взяла сайт LiveLib, отзывы на книгу \"девушка в поезде\".\n",
        "\n",
        "Напишем штуку, которая их собирает"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6C0Xcrx9DMr"
      },
      "source": [
        "def html_collect():\n",
        "  result = requests.get('https://www.livelib.ru/book/1001526145/reviews-devushka-v-poezde-pola-hokins')\n",
        "  result.encoding = 'utf-8'\n",
        "  prob = result.text\n",
        "\n",
        "  html = [prob]\n",
        "  for i in range(2, 20):\n",
        "    link = 'https://www.livelib.ru/book/1001526145/reviews/~'+str(i)+'#reviews'\n",
        "    result = requests.get(link)\n",
        "    result.encoding = 'utf-8'\n",
        "    html.append(result.text)\n",
        "  return(html)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRXI89gxR6GW"
      },
      "source": [
        "Один раз соберем их чтобы лишний раз потом не дергать"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Y5AbKN_Ug2"
      },
      "source": [
        "temp = html_collect()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1vmJeWSR_6e"
      },
      "source": [
        "Эта функция ищет в коде страницы то, что нам нужно: сами отзывы и оценки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McMHzRCr9we_"
      },
      "source": [
        "def rev_search(html):\n",
        "  revs = []\n",
        "  for i in html:\n",
        "    rev_all = re.compile('<span class=\"lenta-card__mymark\">(.*?)</span>.*?<div id=\"lenta-card__text-review-escaped\">.*?<p><p>(.*?)</p></p>', flags = re.DOTALL)\n",
        "    revs.append(rev_all.findall(i))\n",
        "  return(revs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrzL44cUSJPr"
      },
      "source": [
        "Эта функция аккуратно собирает их в список"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRIcNt9RAKeb"
      },
      "source": [
        "def make_rev_list(revs):\n",
        "  revlist = []\n",
        "  for i in revs[0]:\n",
        "    revlist.append(i)\n",
        "  for i in range(1, len(revs)):\n",
        "    for j in range(1, len(revs[i])):\n",
        "      revlist.append(revs[i][j])\n",
        "  return(revlist)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elu6SdGSSM7b"
      },
      "source": [
        "Эта функция чистит содержимое от тегов и переносов строки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jA7zK9k-9R6"
      },
      "source": [
        "def rev_clean(revs):\n",
        "  clean_revs=[]\n",
        "  for i in revs:\n",
        "    x = re.sub(r'\\n', '', i[0])\n",
        "    x = re.sub(' ', '', x)\n",
        "    y = re.sub('<.*?>', '', i[1])\n",
        "    y = re.sub('\\n', ' ', y)\n",
        "    y = re.sub('  ', ' ', y)\n",
        "    clean_revs.append([y, x])\n",
        "  return(clean_revs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slWbHNtTSSUc"
      },
      "source": [
        "Эта функция считает, что оценка 4 или выше это положительный отзыв, 2.5 или ниже --- отрицательный"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud5Mz0g1Ax5_"
      },
      "source": [
        "def rating(x):\n",
        "  if float(x) >= 4:\n",
        "    r = 'good'\n",
        "  elif float(x) <= 2.5:\n",
        "    r = 'bad'\n",
        "  else:\n",
        "    r = ''\n",
        "  return(r)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxhIFk2wSfHh"
      },
      "source": [
        "Эта функция находит создает списки положительных и отрицательных рецензий"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8HnTTYgBWa8"
      },
      "source": [
        "def find_polar(revs):\n",
        "  good = [i for i in revs if rating(i[1]) == 'good']\n",
        "  bad = [i for i in revs if rating(i[1]) == 'bad']\n",
        "  return(good, bad)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2cilkdhSx_g"
      },
      "source": [
        "Эта функция делает нам списки из 30 положительных и 30 отрицательных отзывов как надо в задании"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd_51kjNExUJ"
      },
      "source": [
        "def make_data(good, bad):\n",
        "  good1 = good[:31]\n",
        "  del good1[24]\n",
        "  bad1 = bad[:30]\n",
        "  test1 = good[35:40] + bad[31:36]\n",
        "  return good1, bad1, test1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQActVm1SzpX"
      },
      "source": [
        "Эта функция разбивает отзывы определенной полярности на слова, приводит их к нижнему регистру, чистит и лемматизирует"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1Ax_pG9FepY"
      },
      "source": [
        "def polar_words(polar):\n",
        "  pwords = []\n",
        "  for i in polar:\n",
        "    pw = word_tokenize(i[0])\n",
        "    pwords.extend(pw)\n",
        "  smallpwords = [w.lower() for w in pwords if w.isalpha()]\n",
        "  polarwords = [morph.parse(w)[0].normal_form for w in smallpwords] \n",
        "  return polarwords"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv3qTyjNTFe1"
      },
      "source": [
        "Эта функция чистит списки от слов, которые есть в списке другой полярности (то есть оставляет только слова из положительных или отрицательных отзывов)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPD8Zr2nIpcj"
      },
      "source": [
        "def only_words(polar1, polar2):\n",
        "  return [w for w in polar1 if w not in polar2]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlcfTSyHTWQu"
      },
      "source": [
        "Эта функция убирает слова, которые встречались меньше 3 раз"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjLY_KY4K-dk"
      },
      "source": [
        "def only_freq(polar):\n",
        "  pcounter = Counter(polar)\n",
        "  return [w for w, val in pcounter.items() if val > 2]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeQZ2pR1Tdck"
      },
      "source": [
        "Эта функция считает полярность отзыва. Она считает сколько в нем положительных слов к общему числу положительных слов и аналогично для отрицательных. Так логичнее, потому что отрицательных слов получилось больше, чем положительных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAuxHi_YN23A"
      },
      "source": [
        "def polar(review, good, bad):\n",
        "  rg = 0\n",
        "  rb = 0\n",
        "  wrd = word_tokenize(review)\n",
        "  wrd1 = [w.lower() for w in wrd if w.isalpha()]\n",
        "  lms = [morph.parse(w)[0].normal_form for w in wrd1]\n",
        "  for i in lms:\n",
        "    if i in good:\n",
        "      rg += 1\n",
        "    elif i in bad:\n",
        "      rb += 1\n",
        "  if rg/len(good)>rb/len(bad):\n",
        "    p = 'good'\n",
        "  else:\n",
        "    p = 'bad'\n",
        "  return(p)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLw1pr3sT_es"
      },
      "source": [
        "Эта функция считает точность для тестового набора отзывов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28pU_qJFOgfI"
      },
      "source": [
        "def accuracy(test, good, bad):\n",
        "  acc = 0\n",
        "  for i in test:\n",
        "    if polar(i[0], good, bad) == rating(i[1]):\n",
        "      acc += 1\n",
        "  return(acc/len(test))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UchQLf77ULFk"
      },
      "source": [
        "Здесь мы применяем все функции по очереди чтоб получить результат."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zkuo8tuPhZC",
        "outputId": "b8417b21-4cce-4c05-be38-1cd8a739061e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "reviews = rev_clean(make_rev_list(rev_search(temp))) # все отзывы\n",
        "good0, bad0 = find_polar(reviews) # разделили на хорошие и плохие\n",
        "goodrevs, badrevs, test = make_data(good0, bad0) # создали данные\n",
        "goodwords = polar_words(goodrevs) # нашли слова из хороших отзывов\n",
        "badwords = polar_words(badrevs) # нашли слова из плохих отзывов\n",
        "freqgood = only_freq(only_words(goodwords, badwords)) # взяли только частотные и только из хороших\n",
        "freqbad = only_freq(only_words(badwords, goodwords)) # взяли только частотные и только из плохих\n",
        "accuracy(test, freqgood, freqbad) # посчитали точность"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM1yKvlJUwEU"
      },
      "source": [
        "Ура, неплохая точность, 6/10! Но вряд ли точности, подсчитанной на 10 отзывах можно доверять :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB3KdKDNVAkb"
      },
      "source": [
        "Как улучшить программу?\n",
        "\n",
        "Во-первых, как всегда, взять гораааздо больше рецензий. После этого игра с весами (насколько нечастотные слова можно оставить) имела бы больше смысла (я играла, в моем случае >2 оптимальный вариант).\n",
        "\n",
        "Во-вторых можно попробовать находить частотные для только хороших или плохих отзывов биграммы. Не факт что это поможет, например, в плохих отзывах будет биграмма \"ужасная книга\", но слово \"ужасный\" скорее всего и так относится к плохим словам. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BhwG4taIf6y"
      },
      "source": [
        "#читать отсюда"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-fE1f_TFo_0"
      },
      "source": [
        "Будем улучшать программу добавлением биграмм."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFNZGJi_8vfg",
        "outputId": "0f956890-22e7-4799-8763-b66b9a3f08c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "!pip install git+https://github.com/nlpub/pymystem3"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/nlpub/pymystem3\n",
            "  Cloning https://github.com/nlpub/pymystem3 to /tmp/pip-req-build-tv_ulbnc\n",
            "  Running command git clone -q https://github.com/nlpub/pymystem3 /tmp/pip-req-build-tv_ulbnc\n",
            "Requirement already satisfied (use --upgrade to upgrade): pymystem3==0.2.0 from git+https://github.com/nlpub/pymystem3 in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pymystem3==0.2.0) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (3.0.4)\n",
            "Building wheels for collected packages: pymystem3\n",
            "  Building wheel for pymystem3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymystem3: filename=pymystem3-0.2.0-cp36-none-any.whl size=9922 sha256=cde8bae6d4a612f7dd96ce436bb0c518ec5c45dfe1a186fa7e26f09c6af34f03\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-21ojnsqo/wheels/7d/75/c2/216a594291dee680749ce12c60d16125cfe1f363059e7163dc\n",
            "Successfully built pymystem3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mCwlBxw8-NE",
        "outputId": "4042fff4-4b75-48f3-c6c2-18f4f96ed11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from pymystem3 import Mystem\n",
        "m2 = Mystem()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1uOUWjO9Cgn",
        "outputId": "2b1ad915-687b-4703-8326-2ddf8bcb6aff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!cp mystem /root/.local/bin/mystem"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-18 18:09:13--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.244, 5.45.205.242, 5.45.205.241, ...\n",
            "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.244|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://cache-mskm906.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz [following]\n",
            "--2020-10-18 18:09:14--  http://cache-mskm906.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving cache-mskm906.cdn.yandex.net (cache-mskm906.cdn.yandex.net)... 5.45.220.16, 2a02:6b8:0:2002::17\n",
            "Connecting to cache-mskm906.cdn.yandex.net (cache-mskm906.cdn.yandex.net)|5.45.220.16|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16457938 (16M) [application/octet-stream]\n",
            "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz’\n",
            "\n",
            "mystem-3.0-linux3.1 100%[===================>]  15.70M  29.4MB/s    in 0.5s    \n",
            "\n",
            "2020-10-18 18:09:14 (29.4 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz’ saved [16457938/16457938]\n",
            "\n",
            "mystem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPqfe2RZ7XNV"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsjRCq4AF5Dy"
      },
      "source": [
        "Лемматизируем и попостэгаем текст"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9APaHLWi9fxd"
      },
      "source": [
        "def myst(rutext):\n",
        "  ana = m2.analyze(rutext)\n",
        "  myswordpos = []\n",
        "  for word in ana:\n",
        "    if 'analysis' in word:\n",
        "      if word['analysis'] == []:\n",
        "        lex = word['text']\n",
        "        pos = ''\n",
        "      else:\n",
        "        gr = word['analysis'][0]['gr']\n",
        "        pos = gr.split('=')[0].split(',')[0]\n",
        "        lex = word['analysis'][0]['lex']\n",
        "      myswordpos.append([word['text'], pos, lex])\n",
        "  return(myswordpos)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkr2pJm1GIc9"
      },
      "source": [
        "Функция, которая находит в тексте биграммы типа прил+сущ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c03voIuC9zZS"
      },
      "source": [
        "def adj_noun (sent):\n",
        "  chunks = []\n",
        "  words = myst(sent)\n",
        "  #print(words)\n",
        "  for i in range(len(words)-1):\n",
        "    if words[i][1] == 'A' and words[i+1][1] == 'S':\n",
        "      chunks.append(words[i][2]+' '+words[i+1][2])\n",
        "  return(chunks)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQp3tVlwGPJC"
      },
      "source": [
        "Функция, которая из данного списка рецензий сделает два списка: список подходящих биграмм и список подходящих биграмм, которые встречаются больше одного раза."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjwddeSN981G"
      },
      "source": [
        "def AN_get(revs):\n",
        "  an = []\n",
        "  anmore = []\n",
        "  for i in revs:\n",
        "    sents = sent_tokenize(i[0])\n",
        "    for j in sents:\n",
        "      if adj_noun(j) != []:\n",
        "        for k in adj_noun(j):\n",
        "          if k not in an:\n",
        "            an.append(k)\n",
        "          elif k not in anmore:\n",
        "            anmore.append(k)\n",
        "          #print(k)\n",
        "  return(an, anmore)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwGTN0oGrc1"
      },
      "source": [
        "Применим эти функции и получим списки подходящих биграмм, которые встречаются только в отзывах своей полярности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlO0s8drDVlx",
        "outputId": "4e72eb95-8725-4378-ff69-84b499ce9e48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "angood, goodmore = AN_get(goodrevs)\n",
        "anbad, badmore = AN_get(badrevs)\n",
        "angoodonly = []\n",
        "anbadonly = []\n",
        "for i in goodmore:\n",
        "  if i not in anbad:\n",
        "    angoodonly.append(i)\n",
        "for i in badmore:\n",
        "  if i not in angood:\n",
        "    anbadonly.append(i)\n",
        "print(angoodonly)\n",
        "print(anbadonly)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['разрушительный подозрение', 'сюжетный поворот', 'разный человек']\n",
            "['разный женщина', 'литературный язык']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm-0CAz-G4xM"
      },
      "source": [
        "Сделаем всё то же самое для биграмм типа (любое слово)+книга"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7NSWPs2AMKc"
      },
      "source": [
        "def any_kniga (sent):\n",
        "  chunks = []\n",
        "  words = myst(sent)\n",
        "  #print(words)\n",
        "  for i in range(len(words)-1):\n",
        "    if words[i+1][2] == 'книга':\n",
        "      chunks.append(words[i][2]+' '+words[i+1][2])\n",
        "  return(chunks)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSiOnIi5AZUa"
      },
      "source": [
        "def any_kniga_get(revs):\n",
        "  an = []\n",
        "  anmore = []\n",
        "  for i in revs:\n",
        "    sents = sent_tokenize(i[0])\n",
        "    for j in sents:\n",
        "      if any_kniga(j) != []:\n",
        "        for k in any_kniga(j):\n",
        "          if k not in an:\n",
        "            an.append(k)\n",
        "          elif k not in anmore:\n",
        "            anmore.append(k)\n",
        "          #print(k)\n",
        "  return(an, anmore)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hda5d0ul8xGj",
        "outputId": "2b1f3880-cc7a-42cc-caca-9c38ccddc9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "akgood, goodakmore = any_kniga_get(goodrevs)\n",
        "akbad, badakmore = any_kniga_get(badrevs)\n",
        "akgoodonly = []\n",
        "akbadonly = []\n",
        "for i in goodakmore:\n",
        "  if i not in akbad:\n",
        "    akgoodonly.append(i)\n",
        "for i in badakmore:\n",
        "  if i not in akgood:\n",
        "    akbadonly.append(i)\n",
        "print(akgoodonly)\n",
        "print(akbadonly)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['сюжет книга', 'что книга']\n",
            "['конец книга', 'середина книга', 'плюс книга']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wnJ5kzZHChy"
      },
      "source": [
        "Сделаем то же для биграмм типа (любое слово)+сюжет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQd3CH5D9jLs"
      },
      "source": [
        "def any_plot (sent):\n",
        "  chunks = []\n",
        "  words = myst(sent)\n",
        "  #print(words)\n",
        "  for i in range(len(words)-1):\n",
        "    if words[i+1][2] == 'сюжет':\n",
        "      chunks.append(words[i][2]+' '+words[i+1][2])\n",
        "  return(chunks)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkgQPFrl9un1"
      },
      "source": [
        "def any_plot_get(revs):\n",
        "  an = []\n",
        "  anmore = []\n",
        "  for i in revs:\n",
        "    sents = sent_tokenize(i[0])\n",
        "    for j in sents:\n",
        "      if any_plot(j) != []:\n",
        "        for k in any_plot(j):\n",
        "          if k not in an:\n",
        "            an.append(k)\n",
        "          elif k not in anmore:\n",
        "            anmore.append(k)\n",
        "          #print(k)\n",
        "  return(an, anmore)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBmHdhR994S8",
        "outputId": "967adfe7-3f9a-4343-ebde-2eba8cd294a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "apgood, goodapmore = any_plot_get(goodrevs)\n",
        "apbad, badapmore = any_plot_get(badrevs)\n",
        "apgoodonly = []\n",
        "apbadonly = []\n",
        "for i in goodapmore:\n",
        "  if i not in badapmore:\n",
        "    apgoodonly.append(i)\n",
        "for i in badapmore:\n",
        "  if i not in goodapmore:\n",
        "    apbadonly.append(i)\n",
        "print(apgoodonly)\n",
        "print(apbadonly)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['и сюжет', 'в сюжет']\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihkvH_LjHJEA"
      },
      "source": [
        "Соединим списки полярных биграмм."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbsMbKpX-q2H",
        "outputId": "7f46e25c-25c2-4d2f-ad28-7e8b7331b330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "badbi = angoodonly + apbadonly + akbadonly\n",
        "goodbi = anbadonly + apgoodonly + akgoodonly\n",
        "print(badbi)\n",
        "print(goodbi)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['разрушительный подозрение', 'сюжетный поворот', 'разный человек', 'конец книга', 'середина книга', 'плюс книга']\n",
            "['разный женщина', 'литературный язык', 'и сюжет', 'в сюжет', 'сюжет книга', 'что книга']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8HeBtl9HkTX"
      },
      "source": [
        "Напишем новую функцию (точнее отредактируем старую), которая будет считать полярность отзыва с учетом биграмм."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpVbRSQb-TUw"
      },
      "source": [
        "def polar2(review, good, bad, goodbi, badbi):\n",
        "  rg = 0\n",
        "  rb = 0\n",
        "  wrd = word_tokenize(review)\n",
        "  wrd1 = [w.lower() for w in wrd if w.isalpha()]\n",
        "  lms = [morph.parse(w)[0].normal_form for w in wrd1]\n",
        "  for i in lms:\n",
        "    if i in good:\n",
        "      rg += 1\n",
        "    elif i in bad:\n",
        "      rb += 1\n",
        "  sents = sent_tokenize(review)\n",
        "  for i in sents:\n",
        "    for j in (adj_noun(i)+any_kniga(i)+any_plot(i)):\n",
        "      if j in goodbi:\n",
        "        rg += 1\n",
        "        print(j)\n",
        "      elif j in badbi:\n",
        "        rb += 1\n",
        "        print(j)\n",
        "  if rg/(len(good)+len(goodbi))>rb/(len(bad)+len(badbi)):\n",
        "    p = 'good'\n",
        "  else:\n",
        "    p = 'bad'\n",
        "  return(p)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCOlYEuHHuT4"
      },
      "source": [
        "Напишем новую функцию, кторая будет считать точность используя новую функцию polar2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq4TzMdIE1MJ"
      },
      "source": [
        "def accuracy2(test, good, bad):\n",
        "  acc = 0\n",
        "  for i in test:\n",
        "    if polar2(i[0], good, bad, goodbi, badbi) == rating(i[1]):\n",
        "      acc += 1\n",
        "  return(acc/len(test))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfqbdq7TH2ZX"
      },
      "source": [
        "Посчитаем новую точность"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8PFFePoERXJ",
        "outputId": "56e05028-72b4-4638-c530-4d3df2aadd24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy2(test, freqgood, freqbad)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Oe-LYp9H5r4"
      },
      "source": [
        "Тадам, она такая же. Кто бы сомневался))))))))))\n",
        "\n",
        "Но наверняка всё было не зря и при большем кол-ве отзывов точность была бы выше."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd88DrcPIp0m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}